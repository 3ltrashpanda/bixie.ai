# ğŸ›¡ï¸ Bixie â€“ Autonomous Vulnerability Detection Framework

**Bixie** is an AI-powered cybersecurity research agent designed to automatically discover vulnerabilities in binary executables, source code, and cloud configurations. It blends machine learning, static/dynamic analysis, and cloud misconfiguration detection into an extensible agent-based architecture.

Inspired by modern AI penetration testing frameworks,  Bixie is built for red teams, threat researchers, and security engineers who want scalable automation with explainable results.

---

## âš™ï¸ Features

- ğŸ” Binary analysis using SAFE/VulBERT embeddings, Ghidra, and BinDiff-style clustering  
- ğŸ§  Code vulnerability detection via semantic and AST-based analysis  
- â˜ï¸ Cloud config scanning (Terraform, AWS, Azure) for misconfigs and privilege paths  
- ğŸª Extensible modules for CI/CD integration, alerting, and custom benchmarks  
- ğŸ§ª Real-world CVE benchmarking suite included  

---

## ğŸš€ Getting Started

### 1. Clone the Project

```bash
git clone https://github.com/your-org/bixie.git
cd bixie

2. Install Dependencies

pip install -r requirements.txt

Optional: use conda or virtualenv.
3. Build Docker Images

docker-compose build

This builds containers for:

    Binary analysis (with Ghidra or Binwalk)

    Source scanning (Bandit, Semgrep, custom NLP)

    Cloud scanning (Checkov, custom Terraform logic)

4. Run the Agent

You can run a full scan locally or as a container:

python -m bixie.agent_core --target ./datasets/code_vulns/

Or use:

./scripts/run_agent.sh

5. Run Benchmarks

Use the benchmark suite to test Bixie against known vulnerable datasets:

cd ../bixie_benchmark/
./scripts/run_benchmark.sh
python scripts/eval_metrics.py

## Benchmarking Multiple ELF Files

Place your `.o` or `.elf` files anywhere under the `data/` directory (including subdirectories).  
Run the benchmark script:

```bash
python benchmark.py
```

The script will automatically discover and benchmark all ELF files under `data/`.

ğŸ§± Repo Structure

bixie/
â”œâ”€â”€ agent_core.py            # Main agent logic (dispatch, state, execution)
â”œâ”€â”€ config.py                # Runtime and integration settings
â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ binary_scanner.py
â”‚   â”œâ”€â”€ code_scanner.py
â”‚   â”œâ”€â”€ cloud_scanner.py
â”‚   â””â”€â”€ result_parser.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ safe_embedder.py
â”‚   â”œâ”€â”€ vulbert_infer.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ integrations/
â”‚   â”œâ”€â”€ github.py
â”‚   â”œâ”€â”€ cloud_apis.py
â”‚   â”œâ”€â”€ siem.py
â”‚   â””â”€â”€ messaging.py
â”œâ”€â”€ docker/                  # Dockerfiles for agent components
â”œâ”€â”€ scripts/                 # CLI helpers
â”œâ”€â”€ tests/                   # Unit tests
â””â”€â”€ notebooks/               # Experiments, clustering, visualizations

ğŸ§  How to Extend Bixie
â• Add New Scan Module

    Create a new scanner under bixie/tasks/your_scanner.py

    Implement run() interface that returns findings in standard format

    Register it inside agent_core.py

ğŸ”Œ Add Cloud Provider Support

Extend cloud_apis.py and map to your providerâ€™s API (e.g., GCP, Azure).
ğŸ” Add New ML Model

    Drop model in models/ (ONNX, PyTorch, or Hugging Face format)

    Create wrapper script to load and use embeddings

    Optionally integrate into the clustering pipeline

ğŸ“£ Send Results to External Tools

Use integrations/siem.py or messaging.py to push to:

    Sentinel

    Splunk

    Slack/MS Teams

    Webhooks

ğŸ’¡ Future Work & Ideas
Area	Idea
ML Expansion	Integrate GNN-based models like VulBERTa, or fine-tune SAFE on your binary corpus
Fuzzing	Add AFL++ or libFuzzer hooks to automatically fuzz and crash test identified inputs
Exploitation	Autonomous payload generation and exploit validation (XSS, RCE, IDOR)
Voice Interface	Voice control for operator prompts via Whisper + TTS
SIEM Loop	Auto-ingest and enrich live alert data to prioritize agent scans (threat intel loop)
K8s Defender	Build a mode for Kubernetes misconfiguration and in-cluster privilege path analysis
HackerOne AI	Align findings to bug bounty platforms with templated report output
